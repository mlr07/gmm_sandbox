{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## gmm sandbox\n",
    "\n",
    "focus on making modules and importing\n",
    "\n",
    "use kb's stuff as a base\n",
    "\n",
    "for each log in dir:\n",
    "\n",
    "1. load logs \n",
    "2. process logs\n",
    "3. construct gmm\n",
    "4. run gmm\n",
    "5. plot results\n",
    "\n",
    "look for messed up logs\n",
    "\n",
    "consider results and think about what it means"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "c:\\Users\\mrhoa\\Desktop\\gmm_sandbox\\notebooks\nc:\\Users\\mrhoa\\Desktop\\gmm_sandbox\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# run cell once or path will break\n",
    "print(os.getcwd())\n",
    "os.chdir(Path(os.getcwd()).parent)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.input import load_log\n",
    "from common.model import interval, scale, pca, pca_rank, gmm\n",
    "from common.plot import plot_pca_2D, plot_pca_3D, plot_pca_rank, plot_curves_prob\n",
    "from common.output import combine_curves_prob, combine_pca_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LOG LOADED\n",
      "PCA COMPLETE\n",
      "GMM COMPLETE\n",
      "LOGS AND CLUSTERS MERGED\n",
      "PCA AND CLUSTERS MERGED\n"
     ]
    }
   ],
   "source": [
    "# load log from data and init data dictionary\n",
    "cols = [\"SP\", \"GR\", \"RT90\", \"NPHI_COMP\", \"RHOB\", \"PE\"]\n",
    "data = \"./logs/Lazy_D_400222042.las\"\n",
    "lazy = load_log(data, cols)\n",
    "\n",
    "# grab interval of log by index\n",
    "lazy = interval(lazy, top=8000, bot=9000)\n",
    "\n",
    "# # standard scale log with defaults\n",
    "lazy = scale(lazy)\n",
    "\n",
    "# # run 3 component pca with defaults\n",
    "lazy = pca(lazy)\n",
    "\n",
    "# # run feature rank on pca\n",
    "lazy = pca_rank(lazy)\n",
    "\n",
    "# # run gmm on scaled curves\n",
    "lazy = gmm(lazy, n=4)\n",
    "\n",
    "# # merge gmm clusters to base curves \n",
    "lazy = combine_curves_prob(lazy)\n",
    "\n",
    "# # merge gmm clusters to pca components\n",
    "lazy = combine_pca_prob(lazy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "las: <class 'lasio.las.LASFile'>\nwell_name: LAZY-D ZN 3-9\nbase_curves: <class 'pandas.core.frame.DataFrame'>\ninterval_top: <class 'int'>\ninterval_bot: <class 'int'>\nscaled_curves: <class 'numpy.ndarray'>\npca_curves: <class 'numpy.ndarray'>\npca_expvar: <class 'numpy.ndarray'>\npca_rank: <class 'pandas.core.frame.DataFrame'>\nsoft_clusters: <class 'numpy.ndarray'>\nhard_clusters: <class 'numpy.ndarray'>\ncluster_n: <class 'int'>\nmerged_curves: <class 'pandas.core.frame.DataFrame'>\nmerged_pca: <class 'pandas.core.frame.DataFrame'>\n--------------------------------------------------\nbase df: (2001, 6)\nsoft arr: (2001, 4)\nhard arr: (2001,)\npca arr: (2001, 6)\npca expvar: (2001, 6)\npca rank: (6, 6)\nmerged df: (2001, 8)\nmerged pca: (2001, 8)\n"
     ]
    }
   ],
   "source": [
    "for k,v in lazy.items():\n",
    "    if not isinstance(v, str):\n",
    "        print(f\"{k}: {type(v)}\")\n",
    "    else:\n",
    "        print(f\"{k}: {v}\")\n",
    "\n",
    "print(\"-\"*50)\n",
    "\n",
    "# TODO: work into loop above\n",
    "print(f\"base df: {lazy['base_curves'].shape}\")\n",
    "print(f\"soft arr: {lazy['soft_clusters'].shape}\")\n",
    "print(f\"hard arr: {lazy['hard_clusters'].shape}\")\n",
    "print(f\"pca arr: {lazy['pca_curves'].shape}\")\n",
    "print(f\"pca expvar: {lazy['pca_curves'].shape}\")\n",
    "print(f\"pca rank: {lazy['pca_rank'].shape}\")\n",
    "print(f\"merged df: {lazy['merged_curves'].shape}\")\n",
    "print(f\"merged pca: {lazy['merged_pca'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[37.95522952 35.45408361]\n[37.95522952 35.45408361 15.14142878  6.93065833  2.90519228  1.61340748]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7340931313391792"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "pca_var = lazy[\"pca_expvar\"]\n",
    "print(pca_var[0:2]*100)\n",
    "print(pca_var*100)\n",
    "\n",
    "pca_var[0:2].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = lazy[\"merged_curves\"]\n",
    "test = list(range(0,len(df[\"soft_clusters\"].iloc[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.9999999999791986, 2.080126732267453e-11]"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df[\"soft_clusters\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             SP        GR    RT90  NPHI_COMP    RHOB      PE  \\\n",
       "DEPT                                                           \n",
       "8000.0  60.0192  109.0224  3.5030     0.2423  2.5642  3.0618   \n",
       "8000.5  59.7120  110.2059  3.5513     0.2369  2.5743  3.0574   \n",
       "8001.0  59.3496  105.2788  3.6874     0.2282  2.5809  3.2409   \n",
       "8001.5  59.0965   99.6273  3.8342     0.2292  2.5701  3.3143   \n",
       "8002.0  58.7665  101.3662  3.9282     0.2203  2.5604  3.1588   \n",
       "\n",
       "                                       soft_clusters  hard_clusters  \n",
       "DEPT                                                                 \n",
       "8000.0  [0.9999999999791986, 2.0801267322674972e-11]              0  \n",
       "8000.5  [0.9999999999883162, 1.1683742195077445e-11]              0  \n",
       "8001.0   [0.9999999999913798, 8.620215993188577e-12]              0  \n",
       "8001.5   [0.9999999999772258, 2.277430636696767e-11]              0  \n",
       "8002.0  [0.9999999999983471, 1.6527950687074862e-12]              0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SP</th>\n      <th>GR</th>\n      <th>RT90</th>\n      <th>NPHI_COMP</th>\n      <th>RHOB</th>\n      <th>PE</th>\n      <th>soft_clusters</th>\n      <th>hard_clusters</th>\n    </tr>\n    <tr>\n      <th>DEPT</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8000.0</th>\n      <td>60.0192</td>\n      <td>109.0224</td>\n      <td>3.5030</td>\n      <td>0.2423</td>\n      <td>2.5642</td>\n      <td>3.0618</td>\n      <td>[0.9999999999791986, 2.0801267322674972e-11]</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8000.5</th>\n      <td>59.7120</td>\n      <td>110.2059</td>\n      <td>3.5513</td>\n      <td>0.2369</td>\n      <td>2.5743</td>\n      <td>3.0574</td>\n      <td>[0.9999999999883162, 1.1683742195077445e-11]</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8001.0</th>\n      <td>59.3496</td>\n      <td>105.2788</td>\n      <td>3.6874</td>\n      <td>0.2282</td>\n      <td>2.5809</td>\n      <td>3.2409</td>\n      <td>[0.9999999999913798, 8.620215993188577e-12]</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8001.5</th>\n      <td>59.0965</td>\n      <td>99.6273</td>\n      <td>3.8342</td>\n      <td>0.2292</td>\n      <td>2.5701</td>\n      <td>3.3143</td>\n      <td>[0.9999999999772258, 2.277430636696767e-11]</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8002.0</th>\n      <td>58.7665</td>\n      <td>101.3662</td>\n      <td>3.9282</td>\n      <td>0.2203</td>\n      <td>2.5604</td>\n      <td>3.1588</td>\n      <td>[0.9999999999983471, 1.6527950687074862e-12]</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.0\n          PC_0      PC_1      PC_2      PC_3      PC_4      PC_5  \\\n0    -1.300733 -0.338171  0.382435  0.450333  0.175421  0.027178   \n1    -1.312414 -0.464072  0.345749  0.589252  0.203018  0.022468   \n2    -1.149486 -0.698413  0.304472  0.591948 -0.018508  0.117401   \n3    -1.081612 -0.700394  0.392330  0.377510 -0.147085  0.159952   \n4    -1.159827 -0.664438  0.516778  0.284626  0.134482  0.196854   \n...        ...       ...       ...       ...       ...       ...   \n1020 -0.572449  0.674360 -0.471179 -0.025456 -0.438062 -0.198161   \n1021 -0.635409  0.740670 -0.423287 -0.141764 -0.380094 -0.205261   \n1022 -0.706941  0.291603 -0.719860  0.313945 -0.420868 -0.306070   \n1023 -0.855711  0.134836 -0.828577  0.409214 -0.440789 -0.436143   \n1024 -0.861318  0.581115 -0.508841 -0.128034 -0.257188 -0.322479   \n\n      hard_cluster    dept  \n0              0.0  8000.0  \n1              0.0  8000.5  \n2              0.0  8001.0  \n3              0.0  8001.5  \n4              0.0  8002.0  \n...            ...     ...  \n1020           0.0  8510.0  \n1021           0.0  8510.5  \n1022           0.0  8511.0  \n1023           0.0  8511.5  \n1024           0.0  8512.0  \n\n[1023 rows x 8 columns]\n1.0\n          PC_0      PC_1      PC_2      PC_3      PC_4      PC_5  \\\n949  -0.653620 -1.428665 -1.011166  0.669784 -1.010211 -0.340215   \n950  -0.677849 -1.265565 -0.899270  0.426628 -0.868035 -0.278809   \n1025 -0.765054  1.073035 -0.248729 -0.463188 -0.243496 -0.230547   \n1026 -0.746129  1.091737 -0.304924 -0.344601 -0.374002 -0.277988   \n1027 -0.771888  1.168078 -0.270410 -0.448016 -0.475681 -0.322050   \n...        ...       ...       ...       ...       ...       ...   \n1996  0.803495 -0.497859 -2.768386 -0.094406  0.059235 -0.412860   \n1997  0.673517 -0.678263 -2.865732  0.016464  0.122312 -0.503800   \n1998  0.605318 -0.466791 -2.864251  0.160856  0.154997 -0.541141   \n1999  0.566507 -0.286053 -2.801064  0.101455  0.163029 -0.540072   \n2000  0.590921 -0.334675 -2.797503  0.040101  0.145027 -0.510279   \n\n      hard_cluster    dept  \n949            1.0  8474.5  \n950            1.0  8475.0  \n1025           1.0  8512.5  \n1026           1.0  8513.0  \n1027           1.0  8513.5  \n...            ...     ...  \n1996           1.0  8998.0  \n1997           1.0  8998.5  \n1998           1.0  8999.0  \n1999           1.0  8999.5  \n2000           1.0  9000.0  \n\n[978 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "df_pca = lazy[\"merged_pca\"]\n",
    "unique_clusters = df_pca[\"hard_cluster\"].unique()\n",
    "\n",
    "for u in unique_clusters:\n",
    "    print(u)\n",
    "    cluster_mask = df_pca[\"hard_cluster\"] == u\n",
    "    cluster_df = df_pca[cluster_mask]\n",
    "    print(cluster_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = lazy[\"base_curves\"].index.values.reshape((-1,1))\n",
    "depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot 2D pca with clusters\n",
    "plot_pca_2D(lazy, key=\"merged_pca\")\n",
    "\n",
    "# plot 3D pca with clusters\n",
    "plot_pca_3D(lazy, key=\"merged_pca\")\n",
    "\n",
    "# plot pca feature rank\n",
    "plot_pca_rank(lazy, key=\"pca_rank\")\n",
    "\n",
    "# FIXME: adjust curve names in plot\n",
    "# plot base log curves and clusters in log view\n",
    "plot_curves_prob(lazy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "print(plotly.__version__)\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def discrete_colorscale(bvals, colors):\n",
    "    \"\"\"\n",
    "    bvals - list of values bounding intervals/ranges of interest\n",
    "    colors - list of rgb or hex colorcodes for values in [bvals[k], bvals[k+1]],0<=k < len(bvals)-1\n",
    "    returns the plotly  discrete colorscale\n",
    "    \"\"\"\n",
    "    if len(bvals) != len(colors)+1:\n",
    "        raise ValueError('len(boundary values) should be equal to  len(colors)+1')\n",
    "    bvals = sorted(bvals)     \n",
    "    nvals = [(v-bvals[0])/(bvals[-1]-bvals[0]) for v in bvals]  #normalized values\n",
    "    \n",
    "    dcolorscale = [] #discrete colorscale\n",
    "    for k in range(len(colors)):\n",
    "        dcolorscale.extend([[nvals[k], colors[k]], [nvals[k+1], colors[k]]])\n",
    "    return dcolorscale \n",
    "\n",
    "bvals = [2, 15, 40, 65, 90]\n",
    "\n",
    "# NOTE: still need to define the colors manually...\n",
    "colors = ['#09ffff', '#19d3f3', '#e763fa' , '#ab63fa']\n",
    "\n",
    "dcolorsc = discrete_colorscale(bvals, colors)\n",
    "\n",
    "bvals = np.array(bvals)\n",
    "\n",
    "tickvals = [np.mean(bvals[k:k+2]) for k in range(len(bvals)-1)] #position with respect to bvals where ticktext is displayed\n",
    "ticktext = [f'<{bvals[1]}'] + [f'{bvals[k]}-{bvals[k+1]}' for k in range(1, len(bvals)-2)]+[f'>{bvals[-2]}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.random.randint(bvals[0],  bvals[-1]+1, size=(20, 20))\n",
    "\n",
    "heatmap = go.Heatmap(z=z, \n",
    "                     colorscale = dcolorsc, \n",
    "                     colorbar = dict(thickness=25, \n",
    "                                     tickvals=tickvals, \n",
    "                                     ticktext=ticktext))\n",
    "\n",
    "fig = go.Figure(data=[heatmap])\n",
    "fig.update_layout(width=500, height=500)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "g10 = px.colors.qualitative.G10\n",
    "print(type(g10))\n",
    "\n",
    "unique = df[\"hard_clusters\"].unique()\n",
    "\n",
    "colors = [g10[u] for u in unique]\n",
    "print(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
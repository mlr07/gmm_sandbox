{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## gmm sandbox\n",
    "\n",
    "focus on making modules and importing\n",
    "\n",
    "use kb's stuff as a base\n",
    "\n",
    "for each log in dir:\n",
    "\n",
    "1. load logs \n",
    "2. process logs\n",
    "3. construct gmm\n",
    "4. run gmm\n",
    "5. plot results\n",
    "\n",
    "look for messed up logs\n",
    "\n",
    "consider results and think about what it means"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/home/mlr/Desktop/gmm_sandbox/notebooks\n/home/mlr/Desktop/gmm_sandbox\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# run cell once or path will break\n",
    "print(os.getcwd())\n",
    "os.chdir(Path(os.getcwd()).parent)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.load import load_log\n",
    "from common.model import interval, scale, pca, pca_rank, gmm\n",
    "# from common.plot import plot_pca_2D, plot_pca_3D, plot_pca_rank, plot_curves_prob\n",
    "from common.output import combine_curves_prob, combine_pca_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LOG LOADED\n",
      "PCA COMPLETE\n",
      "GMM COMPLETE\n",
      "LOGS AND CLUSTERS MERGED\n",
      "PCA AND CLUSTERS MERGED\n"
     ]
    }
   ],
   "source": [
    "# load log from data and init data dictionary\n",
    "cols = [\"SP\", \"GR\", \"RT90\", \"NPHI_COMP\", \"RHOB\", \"PE\"]\n",
    "data = \"./logs/Lazy_D_400222042.las\"\n",
    "lazy = load_log(data, cols)\n",
    "\n",
    "# grab interval of log by index\n",
    "lazy = interval(lazy, top=8000, bot=9000)\n",
    "\n",
    "# # standard scale log with defaults\n",
    "lazy = scale(lazy)\n",
    "\n",
    "# # run 3 component pca with defaults\n",
    "lazy = pca(lazy)\n",
    "\n",
    "# # run feature rank on pca\n",
    "lazy = pca_rank(lazy)\n",
    "\n",
    "# # run gmm on scaled curves\n",
    "lazy = gmm(lazy, n=4)\n",
    "\n",
    "# # merge gmm clusters to base curves \n",
    "lazy = combine_curves_prob(lazy)\n",
    "\n",
    "# # merge gmm clusters to pca components\n",
    "lazy = combine_pca_prob(lazy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "las: <class 'lasio.las.LASFile'>\nwell_name: LAZY-D ZN 3-9\nbase_curves: <class 'pandas.core.frame.DataFrame'>\ninterval_top: <class 'int'>\ninterval_bot: <class 'int'>\nscaled_curves: <class 'numpy.ndarray'>\npca_curves: <class 'numpy.ndarray'>\npca_expvar: <class 'numpy.ndarray'>\npca_rank: <class 'pandas.core.frame.DataFrame'>\nsoft_clusters: <class 'numpy.ndarray'>\nhard_clusters: <class 'numpy.ndarray'>\ncluster_n: <class 'int'>\nmerged_curves: <class 'pandas.core.frame.DataFrame'>\nmerged_pca: <class 'pandas.core.frame.DataFrame'>\n--------------------------------------------------\nbase df: (2001, 6)\nsoft arr: (2001, 4)\nhard arr: (2001,)\npca arr: (2001, 6)\npca expvar: (2001, 6)\npca rank: (6, 6)\nmerged df: (2001, 8)\nmerged pca: (2001, 8)\n"
     ]
    }
   ],
   "source": [
    "for k,v in lazy.items():\n",
    "    if not isinstance(v, str):\n",
    "        print(f\"{k}: {type(v)}\")\n",
    "    else:\n",
    "        print(f\"{k}: {v}\")\n",
    "\n",
    "print(\"-\"*50)\n",
    "\n",
    "# TODO: work into loop above\n",
    "print(f\"base df: {lazy['base_curves'].shape}\")\n",
    "print(f\"soft arr: {lazy['soft_clusters'].shape}\")\n",
    "print(f\"hard arr: {lazy['hard_clusters'].shape}\")\n",
    "print(f\"pca arr: {lazy['pca_curves'].shape}\")\n",
    "print(f\"pca expvar: {lazy['pca_curves'].shape}\")\n",
    "print(f\"pca rank: {lazy['pca_rank'].shape}\")\n",
    "print(f\"merged df: {lazy['merged_curves'].shape}\")\n",
    "print(f\"merged pca: {lazy['merged_pca'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[2295.  2295.5 2296.  ... 9675.  9675.5 9676. ]\n[0 0 0 ... 1 1 1]\n(14763,)\n(2001,)\n[8000.]\n[9000.]\n8000.0\n9000.0\n(array([11410]),) (array([13410]),)\n"
     ]
    }
   ],
   "source": [
    "import lasio\n",
    "import numpy as np\n",
    "\n",
    "hard_clusters = lazy[\"hard_clusters\"]\n",
    "las = lazy[\"las\"]\n",
    "name = lazy[\"well_name\"]\n",
    "merged_df = lazy[\"merged_curves\"]\n",
    "\n",
    "print(las.index)\n",
    "print(hard_clusters)\n",
    "\n",
    "print(las.index.shape)\n",
    "print(hard_clusters.shape)\n",
    "\n",
    "top_idx = np.where(las.index==8000)\n",
    "bot_idx = np.where(las.index==9000)\n",
    "\n",
    "print(las.index[top_idx])\n",
    "print(las.index[bot_idx])\n",
    "\n",
    "print(merged_df.index.values[0])\n",
    "print(merged_df.index.values[-1])\n",
    "\n",
    "# need to make NaN array down to index top and from index bot to td. \n",
    "# concat or stack NaN arrays and cluster array\n",
    "# test that new cluster array has the same depth dimension as las.index\n",
    "\n",
    "# then merge try and output a modifed LAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/home/mlr/Desktop/gmm_sandbox/logs\nall the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 14763 and the array at index 37 has size 14659\n/home/mlr/Desktop/gmm_sandbox\n"
     ]
    }
   ],
   "source": [
    "from common.load import cd\n",
    "\n",
    "try:\n",
    "    with cd(os.path.join(os.getcwd(),\"logs\")):\n",
    "        print(os.getcwd())\n",
    "        new_las = las.add_curve(\"HARD_CLUSTER\", hard_clusters, unit=\"int\", descr=\"zone clusters\")\n",
    "        print(las.data.shape)\n",
    "        new_las.write(f\"MODIFIED_{name}.las\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(80,)"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "import numpy as np\n",
    "depths = np.arange(10, 50, 0.5)\n",
    "synth = np.log10(depths)*5+np.random.random(len(depths))\n",
    "synth[:8] = np.nan\n",
    "synth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[3795.52295228 3545.40836111]\n[3795.52295228 3545.40836111 1514.1428778   693.06583307  290.51922796\n  161.34074779]\n['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6']\nTrue\n['PC1 (38.0%)', 'PC2 (35.5%)', 'PC3 (15.1%)', 'PC4 (6.9%)', 'PC5 (2.9%)', 'PC6 (1.6%)']\n"
     ]
    }
   ],
   "source": [
    "pca_var = lazy[\"pca_expvar\"]*100\n",
    "print(pca_var[0:2]*100)\n",
    "print(pca_var*100)\n",
    "\n",
    "rank_df = lazy[\"pca_rank\"]\n",
    "cols = rank_df.columns.values.tolist()\n",
    "print(cols)\n",
    "\n",
    "print(len(cols)==len(pca_var))\n",
    "\n",
    "combine = [f\"{col} ({var:.1f}%)\" for col, var in zip(cols,pca_var)]\n",
    "print(combine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = lazy[\"merged_curves\"]\n",
    "test = list(range(0,len(df[\"soft_clusters\"].iloc[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[1.0039525895920558e-157, 3.585934934702599e-69, 1.0, 1.1861264879369834e-41]"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "df[\"soft_clusters\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pca = lazy[\"merged_pca\"]\n",
    "# df_pca[\"dept\"].astype(str).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = lazy[\"base_curves\"].index.values.reshape((-1,1))\n",
    "depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot 2D pca with clusters\n",
    "plot_pca_2D(lazy, key=\"merged_pca\")\n",
    "\n",
    "# plot 3D pca with clusters\n",
    "plot_pca_3D(lazy, key=\"merged_pca\")\n",
    "\n",
    "# plot pca feature rank\n",
    "plot_pca_rank(lazy, key=\"pca_rank\")\n",
    "\n",
    "# FIXME: adjust curve names in plot\n",
    "# plot base log curves and clusters in log view\n",
    "plot_curves_prob(lazy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "print(plotly.__version__)\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def discrete_colorscale(bvals, colors):\n",
    "    \"\"\"\n",
    "    bvals - list of values bounding intervals/ranges of interest\n",
    "    colors - list of rgb or hex colorcodes for values in [bvals[k], bvals[k+1]],0<=k < len(bvals)-1\n",
    "    returns the plotly  discrete colorscale\n",
    "    \"\"\"\n",
    "    if len(bvals) != len(colors)+1:\n",
    "        raise ValueError('len(boundary values) should be equal to  len(colors)+1')\n",
    "    bvals = sorted(bvals)     \n",
    "    nvals = [(v-bvals[0])/(bvals[-1]-bvals[0]) for v in bvals]  #normalized values\n",
    "    \n",
    "    dcolorscale = [] #discrete colorscale\n",
    "    for k in range(len(colors)):\n",
    "        dcolorscale.extend([[nvals[k], colors[k]], [nvals[k+1], colors[k]]])\n",
    "    return dcolorscale \n",
    "\n",
    "bvals = [2, 15, 40, 65, 90]\n",
    "\n",
    "# NOTE: still need to define the colors manually...\n",
    "colors = ['#09ffff', '#19d3f3', '#e763fa' , '#ab63fa']\n",
    "\n",
    "dcolorsc = discrete_colorscale(bvals, colors)\n",
    "\n",
    "bvals = np.array(bvals)\n",
    "\n",
    "tickvals = [np.mean(bvals[k:k+2]) for k in range(len(bvals)-1)] #position with respect to bvals where ticktext is displayed\n",
    "ticktext = [f'<{bvals[1]}'] + [f'{bvals[k]}-{bvals[k+1]}' for k in range(1, len(bvals)-2)]+[f'>{bvals[-2]}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.random.randint(bvals[0],  bvals[-1]+1, size=(20, 20))\n",
    "\n",
    "heatmap = go.Heatmap(z=z, \n",
    "                     colorscale = dcolorsc, \n",
    "                     colorbar = dict(thickness=25, \n",
    "                                     tickvals=tickvals, \n",
    "                                     ticktext=ticktext))\n",
    "\n",
    "fig = go.Figure(data=[heatmap])\n",
    "fig.update_layout(width=500, height=500)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "g10 = px.colors.qualitative.G10\n",
    "print(type(g10))\n",
    "\n",
    "unique = df[\"hard_clusters\"].unique()\n",
    "\n",
    "colors = [g10[u] for u in unique]\n",
    "print(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}